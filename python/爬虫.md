[TOC]

## 爬虫项目

### 1. 基本介绍

> **requests 库：** 自动爬取 HTML 页面 & 自动提交网络请求
>
> **BeautifulSoup 库：** 解析 HTML 页面
>
> **re 库：** 正则表达式库，提取页面关键信息
>
> **robots.txt：** 网络爬虫排除标准

### 2. 安装 requests 库

安装完成 Python 过后再命令行中输入：`pip install requests`

> **参考文档：** [requests 文档](https://2.python-requests.org//zh_CN/latest/)

### 3. 安装 BeautifulSoup 库

> BeautifulSoup 库是一个可以从 html 和 xml 中提取数据的 Python 库

安装方法：`pip install beautifulsoup4`

测试是否成功：`import bs4` 如果没有报错即成功

> **参考文档：** [BeautifulSoup 文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)

### 4. urllib 库的使用

urllib 库中包含以下几个模块

`urllib.request ` 打开和读取 url

`urllib.error` 包含了由 urllib.request 所引起的异常

`urllib.parse` 解析 url

`urllib.robotparser` 解析 robot.txt 文件

> **参考文档：** [urllib 库](https://docs.python.org/3.8/library/urllib.html)

### 5. 安装 Python IDE pycharm

> **官网地址：** [pytharm](http://www.jetbrains.com/pycharm/download/)

### 6. sublime 插件安装

> 在相应的网站上面下载压缩包后，打开 sublime text ，找到 preference 下的 browse packages ，点进去并将压缩包解压到该文件夹 package 下，重新启动 sublime 即可

1. [CodeIntel 自动补全 & 成员/方法提示](http://github.com/SublimeCodeIntel/SublimeCodeIntel)

2. [Emmet 快速编辑 html](https://github.com/emmetio/emmet)

3. [ConvertToUTF8 使得 sublime text 支持 UTF-8 格式](https://github.com/seanliang/ConvertToUTF8)

4. [Sublime-CSS-Format 统一 CSS 格式](https://github.com/mutian/Sublime-CSS-Format)

5. [SublimeREPL 使用 `Ctrl b` 可以运行程序](https://github.com/wuub/SublimeREPL)

6. [BracketHighlighter 高亮显示括号、引号](https://github.com/facelessuser/BracketHighlighter)

### 7. 使用 urllib.request 和 BeautifulSoup 案例

获取 html 网页内容：

```python
# 查找 Python 中的 urllib 库中的 request 模块，只导入一个 urlopen 函数
from urllib.request import urlopen
from bs4 import BeautifulSoup

# 注意：导入 urlopen ，这里可能会产生错误信息，主要有“404 Page Not Found”和“500 Internal Server Error”两种错误
html = urlopen('https://github.com/wangqicc')

# 调用 html.read() 获取网页的 html 内容，并将获取的网页内容传给 BeautifulSoup 对象
bsObject = BeautifulSoup(html.read())

# 从 bsObject 对象中提取出 <h1> 标签
print(bsObject.h1)
```

捕获异常后的代码：

```python
from urllib.request import urlopen
from urllib.error import HTTPError, URLError
from bs4 import BeautifulSoup
# 定义函数时需要在函数头部和尾部留两个空格，否则在 pycharm 中会有警告


def gettitle(url):
    # 捕获 HTTP 异常
    try:
        html = urlopen(url)
    except (HTTPError, URLError) as e:
        print(e)
        return None
    # 捕获对象属性异常
    # 使用 BeautifulSoup 的时候需要指定 XML/HTML/etc. 解析器
    try:
        bsobject = BeautifulSoup(html.read(), "html.parser")
        title = bsobject.h1
    except AttributeError as e:
        print(e)
        return None
    return title


head = gettitle("https://github.com/wangqicc")
if head == None:
	print("title could not be found")
else:
    print(head)
```

### 8. 常用的 BeautifulSoup 方法

> `bsObject.tagName` 例如：`bsObj.h1`(获取 HTML 文档中第一个 h1 标签)

> `bsObject.findAll(tagName, tagAttributes)` 例如：`bsObj.findAll("span", {"class":"green"})`(获取页面中所有指定标签)

### 9. requests 库常用方法

> `requests.get(url, params = None, **kwargs)`
>
> **url：** 拟获取页面的 url 链接
>
> **params：** url 中的额外参数，字典或字节流格式，可选
>
> **\**kwargs：** 12 个控制访问的参数



### 10. 发送网络请求

`import requests`

`req = requests.get('URL')`

创建了一个 response 对象



### 小技巧

1. `Ctrl Z` 可退出 `python`

2. 